{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GAEGAE2675/01SW/blob/main/base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KC51oSTMoaQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# case corpus\n",
        "#data_corpus = load_dataset(\"lbox/lbox_open\", \"case_corpus\")\n",
        "\n",
        "# casename classficiation task\n",
        "data_cn = load_dataset(\"lbox/lbox_open\", \"casename_classification\")\n",
        "\n",
        "# statutes classification task\n",
        "data_st = load_dataset(\"lbox/lbox_open\", \"statute_classification\")\n",
        "\n",
        "# case summarization task\n",
        "data_summ = load_dataset(\"lbox/lbox_open\", \"summarization\")"
      ],
      "metadata": {
        "id": "q7ZgYLxiMvua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet transformers\n",
        "!pip install --quiet sentencepiece\n",
        "!pip install --quiet datasets\n",
        "!pip install --quiet rouge_score\n",
        "!pip install --quiet pytorch-lightning"
      ],
      "metadata": {
        "id": "Co7eL_9fMwsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lbox-kr/lbox_open.git --branch v0.1\n",
        "%cd lbox_open"
      ],
      "metadata": {
        "id": "38WhdlauMwpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from lcube.data_module.data_lbox_open import LBoxOpenDataModule\n",
        "from lcube.model.model_baseline import SeqToSeqBaseline\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "TgHTzwkcMwnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = Namespace()\n",
        "# dataset\n",
        "args.dataset_card = \"lbox/lbox_open\"\n",
        "args.task = \"casename_classification\"  # comment and uncomment following lines depending on the task\n",
        "# args.task = \"statute_classification\"\n",
        "# args.task = \"summarization\"\n",
        "\n",
        "\n",
        "if args.task in [\"casename_classification\", \"statute_classification\"]:\n",
        "    args.input_key = \"facts\"\n",
        "\n",
        "    # model\n",
        "    args.model_card = \"google/mt5-small\"\n",
        "    args.max_input_len = 512\n",
        "    args.max_target_len = 64\n",
        "\n",
        "    # train\n",
        "    args.max_epochs = 10\n",
        "    args.learning_rate = 2e-4\n",
        "    args.batch_size = 8\n",
        "    args.batch_size_eval = 2 * args.batch_size\n",
        "    args.accumulate_grad_batches = 1\n",
        "    args.validation_metric = \"exact_match\"\n",
        "\n",
        "elif args.task == \"summarization\":\n",
        "    args.input_key = \"precedent\"\n",
        "\n",
        "    # model\n",
        "    args.model_card = \"google/mt5-small\"\n",
        "    args.max_input_len = 768\n",
        "    args.max_target_len = 512\n",
        "\n",
        "    # train\n",
        "    args.max_epochs = 10\n",
        "    args.learning_rate = 2e-4\n",
        "    args.batch_size = 1\n",
        "    args.batch_size_eval = 2 * args.batch_size\n",
        "    args.accumulate_grad_batches = 8\n",
        "    args.validation_metric = \"rougeL\"\n",
        "\n",
        "else:\n",
        "    raise ValueError\n",
        "\n",
        "\n",
        "args.tokenizer = transformers.MT5TokenizerFast.from_pretrained(args.model_card)\n",
        "pl.utilities.seed.seed_everything(seed=1, workers=False)"
      ],
      "metadata": {
        "id": "kOYNpqSbMwlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_module = LBoxOpenDataModule(\n",
        "    args.dataset_card,\n",
        "    args.task,\n",
        "    args.tokenizer,\n",
        "    args.max_input_len,\n",
        "    args.max_target_len,\n",
        "    args.batch_size,\n",
        "    args.batch_size_eval,\n",
        ")"
      ],
      "metadata": {
        "id": "OC9An8tfMwjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = transformers.MT5ForConditionalGeneration.from_pretrained(args.model_card)\n",
        "model = SeqToSeqBaseline(\n",
        "    args.task,\n",
        "    backbone,\n",
        "    args.tokenizer,\n",
        "    args.learning_rate,\n",
        "    args.max_target_len,\n",
        "    args.validation_metric\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "jAia4PKpMwgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = pl.callbacks.ModelCheckpoint(\n",
        "    monitor=args.validation_metric,\n",
        "    dirpath=f\"./saved/0/{args.task}\",\n",
        "    save_top_k=1,\n",
        "    mode=\"max\",\n",
        ")\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs = args.max_epochs,\n",
        "    gpus=torch.cuda.device_count(),\n",
        "    accumulate_grad_batches=args.accumulate_grad_batches,\n",
        "    fast_dev_run=not True,\n",
        "    callbacks=callbacks,\n",
        ")"
      ],
      "metadata": {
        "id": "zpT5KM-dMweV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "metadata": {
        "id": "WwDbewiTMwbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.model = model.model.to(device)\n",
        "pr_seqs = model.model.generate(model_inputs[\"input_ids\"],\n",
        "                               max_length=args.max_target_len)\n",
        "prs = args.tokenizer.batch_decode(pr_seqs, skip_special_tokens=True)\n",
        "print(f\"판례를 입력해주세요\\n {input_text}\\n\\n\")\n",
        "print(f\"예상되는 위반법\\n {prs}\")"
      ],
      "metadata": {
        "id": "c0qpl-rSMwZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LDwqTwuOMwWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yBMudxSLMwUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KLghr1DOMwPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fG2Ti1TEMwHM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
